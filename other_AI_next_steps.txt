Let's build the complete frontend and GitHub integration. I'll give you files in chunks.

Part 1: Backend - GitHub & Batch Processing
1.1 Create D:\migratemate\backend\app\services\github_service.py
python"""GitHub repository cloning and processing service."""

import os
import shutil
import tempfile
import subprocess
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)


@dataclass
class RepoFile:
    """Represents a file in a repository."""
    path: str
    relative_path: str
    content: str
    size: int


class GitHubService:
    """Service for cloning and processing GitHub repositories."""
    
    def __init__(self, workspace_dir: str = None):
        self.workspace_dir = workspace_dir or tempfile.mkdtemp(prefix="migratemate_")
    
    def clone_repo(self, repo_url: str, branch: str = "main") -> str:
        """
        Clone a GitHub repository.
        
        Args:
            repo_url: GitHub URL (https://github.com/user/repo)
            branch: Branch to clone
            
        Returns:
            Path to cloned repository
        """
        # Clean URL
        repo_url = repo_url.strip()
        if repo_url.endswith('.git'):
            repo_url = repo_url[:-4]
        
        # Extract repo name
        repo_name = repo_url.rstrip('/').split('/')[-1]
        clone_path = os.path.join(self.workspace_dir, repo_name)
        
        # Remove if exists
        if os.path.exists(clone_path):
            shutil.rmtree(clone_path)
        
        # Clone
        logger.info(f"Cloning {repo_url} to {clone_path}")
        try:
            result = subprocess.run(
                ["git", "clone", "--depth", "1", "--branch", branch, repo_url, clone_path],
                capture_output=True,
                text=True,
                timeout=120
            )
            if result.returncode != 0:
                # Try without branch (use default)
                result = subprocess.run(
                    ["git", "clone", "--depth", "1", repo_url, clone_path],
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                if result.returncode != 0:
                    raise Exception(f"Git clone failed: {result.stderr}")
        except subprocess.TimeoutExpired:
            raise Exception("Clone timeout - repository too large")
        
        return clone_path
    
    def find_python_files(self, repo_path: str, exclude_patterns: List[str] = None) -> List[str]:
        """Find all Python files in a repository."""
        exclude_patterns = exclude_patterns or [
            '__pycache__', '.git', 'venv', 'env', '.env',
            'node_modules', '.pytest_cache', '*.pyc', 'migrations',
            'tests', 'test_*', '*_test.py'
        ]
        
        python_files = []
        repo_path = Path(repo_path)
        
        for py_file in repo_path.rglob('*.py'):
            relative = py_file.relative_to(repo_path)
            
            # Check exclusions
            skip = False
            for pattern in exclude_patterns:
                if pattern in str(relative):
                    skip = True
                    break
            
            if not skip:
                python_files.append(str(py_file))
        
        return sorted(python_files)
    
    def read_file(self, file_path: str, repo_path: str) -> RepoFile:
        """Read a file and return RepoFile object."""
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
        
        relative_path = os.path.relpath(file_path, repo_path)
        
        return RepoFile(
            path=file_path,
            relative_path=relative_path,
            content=content,
            size=len(content)
        )
    
    def detect_flask_project(self, repo_path: str) -> Dict[str, Any]:
        """Detect if repository is a Flask project and find entry points."""
        indicators = {
            'is_flask': False,
            'entry_points': [],
            'has_blueprints': False,
            'has_flask_restful': False,
            'config_files': []
        }
        
        python_files = self.find_python_files(repo_path)
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                # Check for Flask imports
                if 'from flask import' in content or 'import flask' in content:
                    indicators['is_flask'] = True
                    
                    # Check for app creation
                    if 'Flask(__name__)' in content or 'Flask(' in content:
                        indicators['entry_points'].append(
                            os.path.relpath(file_path, repo_path)
                        )
                    
                    # Check for blueprints
                    if 'Blueprint(' in content:
                        indicators['has_blueprints'] = True
                    
                    # Check for Flask-RESTful
                    if 'flask_restful' in content or 'Api(' in content:
                        indicators['has_flask_restful'] = True
                
                # Config files
                basename = os.path.basename(file_path).lower()
                if basename in ['config.py', 'settings.py', 'configuration.py']:
                    indicators['config_files'].append(
                        os.path.relpath(file_path, repo_path)
                    )
                    
            except Exception as e:
                logger.warning(f"Error reading {file_path}: {e}")
        
        return indicators
    
    def cleanup(self, repo_path: str = None):
        """Clean up cloned repository."""
        path = repo_path or self.workspace_dir
        if os.path.exists(path):
            shutil.rmtree(path)


_github_service: Optional[GitHubService] = None

def get_github_service() -> GitHubService:
    global _github_service
    if _github_service is None:
        _github_service = GitHubService()
    return _github_service

1.2 Create D:\migratemate\backend\app\services\migration_service.py
python"""Batch migration service for processing entire projects."""

import os
import asyncio
import zipfile
import tempfile
import shutil
from pathlib import Path
from typing import List, Dict, Any, Optional, Callable
from dataclasses import dataclass, field
from datetime import datetime
import logging

from app.services.github_service import GitHubService, get_github_service
from app.services.code_parser import parse_python_file, detect_flask_routes
from app.agents.migration_agent import get_migration_agent

logger = logging.getLogger(__name__)


@dataclass
class MigrationProgress:
    """Tracks migration progress."""
    total_files: int = 0
    processed_files: int = 0
    total_chunks: int = 0
    processed_chunks: int = 0
    current_file: str = ""
    current_chunk: str = ""
    status: str = "pending"
    errors: List[str] = field(default_factory=list)
    start_time: datetime = field(default_factory=datetime.now)
    
    @property
    def percentage(self) -> float:
        if self.total_chunks == 0:
            return 0
        return (self.processed_chunks / self.total_chunks) * 100


@dataclass 
class MigrationResult:
    """Result of a file migration."""
    source_path: str
    output_path: str
    source_content: str
    migrated_content: str
    chunks_migrated: int
    chunks_failed: int
    confidence: float


class BatchMigrationService:
    """Service for migrating entire projects."""
    
    def __init__(self):
        self.github = get_github_service()
        self.agent = get_migration_agent()
        self.progress: Optional[MigrationProgress] = None
        self._progress_callback: Optional[Callable] = None
    
    def set_progress_callback(self, callback: Callable):
        """Set callback for progress updates."""
        self._progress_callback = callback
    
    def _update_progress(self, **kwargs):
        """Update progress and notify callback."""
        if self.progress:
            for key, value in kwargs.items():
                setattr(self.progress, key, value)
            if self._progress_callback:
                self._progress_callback(self.progress)
    
    async def migrate_github_repo(
        self,
        repo_url: str,
        branch: str = "main",
        source_framework: str = "flask",
        target_framework: str = "fastapi"
    ) -> Dict[str, Any]:
        """
        Migrate a GitHub repository.
        
        Returns:
            Dict with output_path, results, and summary
        """
        self.progress = MigrationProgress(status="cloning")
        self._update_progress()
        
        try:
            # Clone repository
            repo_path = self.github.clone_repo(repo_url, branch)
            self._update_progress(status="analyzing")
            
            # Detect project structure
            detection = self.github.detect_flask_project(repo_path)
            if not detection['is_flask']:
                raise ValueError("Not a Flask project - no Flask imports detected")
            
            # Find Python files
            python_files = self.github.find_python_files(repo_path)
            self._update_progress(total_files=len(python_files), status="migrating")
            
            # Create output directory
            output_dir = tempfile.mkdtemp(prefix="migratemate_output_")
            
            # Migrate each file
            results = []
            for i, file_path in enumerate(python_files):
                self._update_progress(
                    current_file=os.path.relpath(file_path, repo_path),
                    processed_files=i
                )
                
                result = await self._migrate_file(
                    file_path=file_path,
                    repo_path=repo_path,
                    output_dir=output_dir,
                    source_framework=source_framework,
                    target_framework=target_framework
                )
                results.append(result)
            
            self._update_progress(
                processed_files=len(python_files),
                status="packaging"
            )
            
            # Create output ZIP
            zip_path = self._create_output_zip(output_dir, repo_url)
            
            # Cleanup
            self.github.cleanup(repo_path)
            shutil.rmtree(output_dir)
            
            self._update_progress(status="completed")
            
            return {
                "zip_path": zip_path,
                "results": [self._result_to_dict(r) for r in results],
                "summary": {
                    "total_files": len(python_files),
                    "files_migrated": len([r for r in results if r.chunks_migrated > 0]),
                    "total_chunks": sum(r.chunks_migrated + r.chunks_failed for r in results),
                    "chunks_succeeded": sum(r.chunks_migrated for r in results),
                    "chunks_failed": sum(r.chunks_failed for r in results),
                    "average_confidence": sum(r.confidence for r in results) / len(results) if results else 0
                }
            }
            
        except Exception as e:
            logger.error(f"Migration failed: {e}")
            self._update_progress(status="failed", errors=[str(e)])
            raise
    
    async def migrate_uploaded_zip(
        self,
        zip_path: str,
        source_framework: str = "flask",
        target_framework: str = "fastapi"
    ) -> Dict[str, Any]:
        """Migrate an uploaded ZIP file."""
        self.progress = MigrationProgress(status="extracting")
        
        # Extract ZIP
        extract_dir = tempfile.mkdtemp(prefix="migratemate_extract_")
        with zipfile.ZipFile(zip_path, 'r') as zf:
            zf.extractall(extract_dir)
        
        # Find the actual project root (might be nested)
        project_root = self._find_project_root(extract_dir)
        
        self._update_progress(status="analyzing")
        
        # Find Python files
        python_files = self.github.find_python_files(project_root)
        self._update_progress(total_files=len(python_files), status="migrating")
        
        # Create output directory
        output_dir = tempfile.mkdtemp(prefix="migratemate_output_")
        
        # Migrate each file
        results = []
        for i, file_path in enumerate(python_files):
            self._update_progress(
                current_file=os.path.relpath(file_path, project_root),
                processed_files=i
            )
            
            result = await self._migrate_file(
                file_path=file_path,
                repo_path=project_root,
                output_dir=output_dir,
                source_framework=source_framework,
                target_framework=target_framework
            )
            results.append(result)
        
        self._update_progress(processed_files=len(python_files), status="packaging")
        
        # Create output ZIP
        zip_path = self._create_output_zip(output_dir, "uploaded_project")
        
        # Cleanup
        shutil.rmtree(extract_dir)
        shutil.rmtree(output_dir)
        
        self._update_progress(status="completed")
        
        return {
            "zip_path": zip_path,
            "results": [self._result_to_dict(r) for r in results],
            "summary": {
                "total_files": len(python_files),
                "files_migrated": len([r for r in results if r.chunks_migrated > 0]),
            }
        }
    
    async def _migrate_file(
        self,
        file_path: str,
        repo_path: str,
        output_dir: str,
        source_framework: str,
        target_framework: str
    ) -> MigrationResult:
        """Migrate a single file."""
        relative_path = os.path.relpath(file_path, repo_path)
        output_path = os.path.join(output_dir, relative_path)
        
        # Create output directory structure
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # Read source
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            source_content = f.read()
        
        # Check if it's a Flask file
        if 'flask' not in source_content.lower() and '@app.route' not in source_content:
            # Not a Flask file, copy as-is
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(source_content)
            return MigrationResult(
                source_path=relative_path,
                output_path=relative_path,
                source_content=source_content,
                migrated_content=source_content,
                chunks_migrated=0,
                chunks_failed=0,
                confidence=1.0
            )
        
        # Parse into chunks
        chunks = parse_python_file(source_content, relative_path)
        self._update_progress(total_chunks=self.progress.total_chunks + len(chunks))
        
        # Build header
        migrated_parts = [self._generate_fastapi_header()]
        chunks_migrated = 0
        chunks_failed = 0
        total_confidence = 0
        
        for chunk in chunks:
            self._update_progress(
                current_chunk=chunk.name,
                processed_chunks=self.progress.processed_chunks + 1
            )
            
            # Skip non-route chunks for now (copy as-is)
            if '@app.route' not in chunk.content and '@bp.route' not in chunk.content:
                continue
            
            try:
                result = await self.agent.migrate_chunk(
                    project_id=0,
                    job_id=0,
                    source_framework=source_framework,
                    target_framework=target_framework,
                    chunk_id=0,
                    chunk_content=chunk.content,
                    chunk_name=chunk.name,
                    chunk_type=chunk.chunk_type
                )
                
                if result.get('status') == 'completed' and result.get('migrated_code'):
                    migrated_parts.append(result['migrated_code'])
                    chunks_migrated += 1
                    total_confidence += result.get('confidence_score', 0)
                else:
                    chunks_failed += 1
                    migrated_parts.append(f"# TODO: Migration failed for {chunk.name}\n{chunk.content}")
                    
            except Exception as e:
                logger.error(f"Chunk migration failed: {e}")
                chunks_failed += 1
                migrated_parts.append(f"# TODO: Migration error for {chunk.name}\n{chunk.content}")
        
        # Post-process
        migrated_content = "\n\n".join(migrated_parts)
        migrated_content = self._post_process(migrated_content)
        
        # Write output
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(migrated_content)
        
        avg_confidence = total_confidence / chunks_migrated if chunks_migrated > 0 else 0
        
        return MigrationResult(
            source_path=relative_path,
            output_path=relative_path,
            source_content=source_content,
            migrated_content=migrated_content,
            chunks_migrated=chunks_migrated,
            chunks_failed=chunks_failed,
            confidence=avg_confidence
        )
    
    def _generate_fastapi_header(self) -> str:
        """Generate FastAPI file header."""
        return '''"""Auto-migrated from Flask to FastAPI by MigrateMate."""

from fastapi import FastAPI, HTTPException, Request, Depends
from pydantic import BaseModel
from typing import List, Optional

app = FastAPI(title="Migrated API")
'''
    
    def _post_process(self, code: str) -> str:
        """Post-process migrated code."""
        import re
        
        # Fix Flask API references
        code = code.replace('"Welcome to Flask', '"Welcome to FastAPI')
        code = code.replace("'Welcome to Flask", "'Welcome to FastAPI")
        
        # Ensure newlines before decorators
        code = re.sub(r'(\S)(@app\.)', r'\1\n\n\2', code)
        
        # Remove duplicate imports
        lines = code.split('\n')
        seen_imports = set()
        result = []
        for line in lines:
            stripped = line.strip()
            if stripped.startswith('from ') or stripped.startswith('import '):
                if stripped not in seen_imports:
                    seen_imports.add(stripped)
                    result.append(line)
            else:
                result.append(line)
        
        return '\n'.join(result)
    
    def _find_project_root(self, extract_dir: str) -> str:
        """Find the actual project root in extracted ZIP."""
        # Check if there's a single directory at root
        items = os.listdir(extract_dir)
        if len(items) == 1:
            single_item = os.path.join(extract_dir, items[0])
            if os.path.isdir(single_item):
                return single_item
        return extract_dir
    
    def _create_output_zip(self, output_dir: str, project_name: str) -> str:
        """Create output ZIP file."""
        # Clean project name
        project_name = project_name.split('/')[-1].replace('.git', '')
        
        zip_path = os.path.join(
            tempfile.gettempdir(),
            f"{project_name}_fastapi_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
        )
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
            for root, dirs, files in os.walk(output_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, output_dir)
                    zf.write(file_path, arcname)
            
            # Add requirements.txt
            requirements = "fastapi==0.111.0\nuvicorn[standard]==0.30.1\npydantic==2.7.4\n"
            zf.writestr("requirements.txt", requirements)
        
        return zip_path
    
    def _result_to_dict(self, result: MigrationResult) -> Dict[str, Any]:
        """Convert MigrationResult to dict."""
        return {
            "source_path": result.source_path,
            "output_path": result.output_path,
            "chunks_migrated": result.chunks_migrated,
            "chunks_failed": result.chunks_failed,
            "confidence": result.confidence
        }


_batch_service: Optional[BatchMigrationService] = None

def get_batch_migration_service() -> BatchMigrationService:
    global _batch_service
    if _batch_service is None:
        _batch_service = BatchMigrationService()
    return _batch_service

1.3 Update D:\migratemate\backend\app\services\__init__.py
Add these imports at the end:
pythonfrom app.services.github_service import GitHubService, get_github_service
from app.services.migration_service import BatchMigrationService, get_batch_migration_service, MigrationProgress

__all__ = [
    # ... existing exports ...
    "GitHubService", "get_github_service",
    "BatchMigrationService", "get_batch_migration_service", "MigrationProgress",
]

1.4 Create D:\migratemate\backend\app\api\v1\batch.py
python"""Batch migration API endpoints."""

import os
import shutil
from typing import Optional
from fastapi import APIRouter, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.responses import FileResponse
from pydantic import BaseModel, Field

from app.services import get_batch_migration_service

router = APIRouter()


class GitHubMigrateRequest(BaseModel):
    repo_url: str = Field(..., description="GitHub repository URL")
    branch: str = Field(default="main", description="Branch to migrate")
    source_framework: str = Field(default="flask")
    target_framework: str = Field(default="fastapi")


class MigrationStatusResponse(BaseModel):
    status: str
    progress: float
    current_file: str
    current_chunk: str
    total_files: int
    processed_files: int
    errors: list


# Store for active migrations (in production, use Redis)
active_migrations = {}


@router.post("/github")
async def migrate_github_repo(request: GitHubMigrateRequest, background_tasks: BackgroundTasks):
    """Start migration of a GitHub repository."""
    service = get_batch_migration_service()
    
    # Generate migration ID
    import uuid
    migration_id = str(uuid.uuid4())[:8]
    
    async def run_migration():
        try:
            result = await service.migrate_github_repo(
                repo_url=request.repo_url,
                branch=request.branch,
                source_framework=request.source_framework,
                target_framework=request.target_framework
            )
            active_migrations[migration_id] = {
                "status": "completed",
                "result": result
            }
        except Exception as e:
            active_migrations[migration_id] = {
                "status": "failed",
                "error": str(e)
            }
    
    active_migrations[migration_id] = {"status": "starting"}
    background_tasks.add_task(run_migration)
    
    return {"migration_id": migration_id, "status": "started"}


@router.post("/upload")
async def migrate_uploaded_file(
    file: UploadFile = File(...),
    source_framework: str = "flask",
    target_framework: str = "fastapi"
):
    """Migrate an uploaded ZIP file."""
    if not file.filename.endswith('.zip'):
        raise HTTPException(400, "Only ZIP files are supported")
    
    # Save uploaded file
    import tempfile
    temp_path = os.path.join(tempfile.gettempdir(), file.filename)
    with open(temp_path, 'wb') as f:
        content = await file.read()
        f.write(content)
    
    try:
        service = get_batch_migration_service()
        result = await service.migrate_uploaded_zip(
            zip_path=temp_path,
            source_framework=source_framework,
            target_framework=target_framework
        )
        
        return {
            "status": "completed",
            "download_url": f"/api/v1/batch/download?path={result['zip_path']}",
            "summary": result['summary']
        }
    finally:
        os.remove(temp_path)


@router.get("/status/{migration_id}")
async def get_migration_status(migration_id: str):
    """Get status of a migration."""
    if migration_id not in active_migrations:
        raise HTTPException(404, "Migration not found")
    
    migration = active_migrations[migration_id]
    service = get_batch_migration_service()
    progress = service.progress
    
    if progress:
        return MigrationStatusResponse(
            status=progress.status,
            progress=progress.percentage,
            current_file=progress.current_file,
            current_chunk=progress.current_chunk,
            total_files=progress.total_files,
            processed_files=progress.processed_files,
            errors=progress.errors
        )
    
    return migration


@router.get("/download")
async def download_result(path: str):
    """Download migrated project ZIP."""
    if not os.path.exists(path):
        raise HTTPException(404, "File not found")
    
    return FileResponse(
        path=path,
        filename=os.path.basename(path),
        media_type="application/zip"
    )


@router.get("/result/{migration_id}")
async def get_migration_result(migration_id: str):
    """Get migration result with download link."""
    if migration_id not in active_migrations:
        raise HTTPException(404, "Migration not found")
    
    migration = active_migrations[migration_id]
    
    if migration.get("status") != "completed":
        return {"status": migration.get("status"), "error": migration.get("error")}
    
    result = migration.get("result", {})
    return {
        "status": "completed",
        "download_url": f"/api/v1/batch/download?path={result.get('zip_path', '')}",
        "summary": result.get("summary"),
        "files": result.get("results")
    }

1.5 Update D:\migratemate\backend\app\api\v1\__init__.py
python"""API v1 routers."""

from app.api.v1.projects import router as projects_router
from app.api.v1.migrations import router as migrations_router
from app.api.v1.ai import router as ai_router
from app.api.v1.batch import router as batch_router

__all__ = ["projects_router", "migrations_router", "ai_router", "batch_router"]

1.6 Update D:\migratemate\backend\app\main.py
Add the batch router. Find this line:
pythonfrom app.api.v1 import projects_router, migrations_router, ai_router
Replace with:
pythonfrom app.api.v1 import projects_router, migrations_router, ai_router, batch_router
Then add after the other include_router lines:
python    app.include_router(batch_router, prefix="/api/v1/batch", tags=["Batch Migration"])

Part 2: Frontend Setup
2.1 Create Next.js Project
Run in PowerShell:
powershellcd D:\migratemate
npx create-next-app@14 frontend --typescript --tailwind --eslint --app --src-dir --import-alias "@/*"
When prompted:

Use App Router? Yes
Customize default import alias? No


2.2 Install Frontend Dependencies
powershellcd D:\migratemate\frontend
npm install @monaco-editor/react react-diff-viewer-continued lucide-react axios